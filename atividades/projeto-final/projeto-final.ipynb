{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CMCC](http://cmcc.ufabc.edu.br/images/logo_site.jpg)\n",
    "# **Classificação de Eventos em Logs de Interação Capturados por Eye Tracker**\n",
    "\n",
    "### Leandro Marega Ferreira Otani - RA 131710240\n",
    "#### Universidade Federal do ABC - Programa de Pós-graduação em Ciência da Computação - Inteligência na Web e Big-Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O relatório e implementação individual notebook podem ser conferidos na URL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  https://github.com/leandro-otani/BIGDATA2017/tree/master/atividades/projeto-final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Implementação  original - Algoritmo I-VT **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1512264899L, 32, 27], [1512264959L, 317, 27]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from operator import add\n",
    "\n",
    "def euclideanDistance(coordinateA, coordinateB):\n",
    "    return (math.sqrt(math.pow((coordinateB[1] - coordinateA[1]), 2) +\n",
    "        math.pow((coordinateB[2] - coordinateA[2]), 2)))\n",
    "\n",
    "def iterativeVelocityThreshold(dataset, threshold):\n",
    "    mappedVelocities = []\n",
    "    for index, point in enumerate(dataset):\n",
    "        if index < (len(dataset) - 1):\n",
    "            nextPoint = dataset[index+1]\n",
    "            mappedVelocities.append((point, euclideanDistance(nextPoint, point) / abs(point[0] - nextPoint[0])))\n",
    "\n",
    "    classifiedVelocities = []\n",
    "    for index, point in enumerate(mappedVelocities):\n",
    "        label = \"Saccade\" if point[1] > threshold else \"Fixation\"\n",
    "        classifiedVelocities.append((point, label))\n",
    "\n",
    "    count = -1\n",
    "    colapsedFixations = []\n",
    "    saccadeHappened = False\n",
    "\n",
    "    for elem in classifiedVelocities:\n",
    "        if elem[1] == \"Saccade\":\n",
    "            saccadeHappened = True\n",
    "        else:\n",
    "            if len(colapsedFixations) == 0 or saccadeHappened:\n",
    "                count += 1\n",
    "                saccadeHappened = False\n",
    "                colapsedFixations.append([])\n",
    "                colapsedFixations[count] = []\n",
    "            colapsedFixations[count].append(elem[0])\n",
    "\n",
    "    fixations = []\n",
    "    for group in colapsedFixations:\n",
    "        centroid = [0, 0, 0]\n",
    "        for point in group: \n",
    "            centroid[0] = centroid[0] + point[0][0]\n",
    "            centroid[1] = centroid[1] + point[0][1]\n",
    "            centroid[2] = centroid[2] + point[0][2]\n",
    "            \n",
    "        centroid[0] = centroid[0]/len(group)\n",
    "        centroid[1] = centroid[1]/len(group)\n",
    "        centroid[2] = centroid[2]/len(group)\n",
    "        fixations.append(centroid)\n",
    "    return fixations\n",
    "\n",
    "print (iterativeVelocityThreshold([\n",
    "    (1512264894, 30, 27),\n",
    "    (1512264904, 35, 27),\n",
    "    (1512264914, 39, 30),\n",
    "    (1512264924, 30, 31),\n",
    "    (1512264934, 40, 35),\n",
    "    (1512264944, 300, 27),\n",
    "    (1512264954, 315, 27),\n",
    "    (1512264964, 320, 27),\n",
    "    (1512264974, 317, 27)\n",
    "], 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Implementação paralelizada - Algoritmo I-VT **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1512264899L, 32, 27), (1, 1512264959L, 317, 27)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time  \n",
    "from operator import add\n",
    "sc = SparkContext.getOrCreate()\n",
    "def euclideanDistance(baseTuple):\n",
    "    coordinateA = baseTuple[0]\n",
    "    coordinateB = baseTuple[1]\n",
    "\n",
    "    return (math.sqrt(math.pow((coordinateB[1] - coordinateA[1]), 2) +\n",
    "        math.pow((coordinateB[2] - coordinateA[2]), 2)))\n",
    "\n",
    "def parallelizedVelocityThreshold(dataset, threshold):\n",
    "    firstSetRDD = sc.parallelize(dataset[:-1])\n",
    "    secondSetRDD = sc.parallelize(dataset[1:])\n",
    "    zippedRDD = firstSetRDD.zip(secondSetRDD)\n",
    "    \n",
    "    mappedVelocities = zippedRDD.map(lambda x: (x[0],(euclideanDistance(x) / abs(x[1][0] - x[0][0]))))\n",
    "    \n",
    "    classifiedVelocities =  (mappedVelocities\n",
    "                                .map(lambda x: (x[0], \"Saccade\" if x[1] > threshold else \"Fixation\"))\n",
    "                                .sortBy(lambda x: x[0][0])\n",
    "                                .collect())\n",
    "\n",
    "    count = -1\n",
    "    colapsedFixations = []\n",
    "    saccadeHappened = False\n",
    "\n",
    "    for elem in classifiedVelocities:\n",
    "        if elem[1] == \"Saccade\":\n",
    "            saccadeHappened = True\n",
    "        else:\n",
    "            if len(colapsedFixations) == 0 or saccadeHappened:\n",
    "                count += 1\n",
    "                saccadeHappened = False\n",
    "            #print elem\n",
    "            colapsedFixations.append((count,elem[0]))\n",
    "    \n",
    "    colapsedRDD = sc.parallelize(colapsedFixations, 4)\n",
    "    countRDD = sc.parallelize(colapsedFixations, 4).map(lambda x: (x[0], 1)).reduceByKey(add)\n",
    "\n",
    "    sumCentroids = colapsedRDD.reduceByKey(lambda (tsa, xa, ya),(tsb, xb, yb): ((tsa+tsb, xa+xb, ya+yb)))\n",
    "    zippedCentroids = sumCentroids.join(countRDD)\n",
    "    centroids = zippedCentroids.map(lambda (k,v): (k, v[0][0]/v[1], v[0][1]/v[1], v[0][2]/v[1] ))\n",
    "    return centroids.collect()\n",
    "\n",
    "print parallelizedVelocityThreshold([\n",
    "    (1512264894, 30, 27),\n",
    "    (1512264904, 35, 27),\n",
    "    (1512264914, 39, 30),\n",
    "    (1512264924, 30, 31),\n",
    "    (1512264934, 40, 35),\n",
    "    (1512264944, 300, 27),\n",
    "    (1512264954, 315, 27),\n",
    "    (1512264964, 320, 27),\n",
    "    (1512264974, 317, 27)\n",
    "], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
